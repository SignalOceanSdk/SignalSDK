{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HQP3cyCyBRs0"
   },
   "source": [
    "# Ton Charts for Capes Globally\n",
    "\n",
    "## Run this example in [Colab](https://colab.research.google.com/github/SignalOceanSdk/SignalSDK/blob/master/docs/examples/jupyter/VoyagesAPI/TonCharts.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GcrCrw4ABRs8"
   },
   "source": [
    "- Get your personal Signal Ocean API subscription key (acquired [here](https://apis.signalocean.com/profile)) and replace it below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1IgxL444BRs-"
   },
   "outputs": [],
   "source": [
    "signal_ocean_api_key = \"\"  # replace with your subscription key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hvT2ynCmBRtC"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gr4mWUgyBc-1"
   },
   "source": [
    "- Install the Signal Ocean SDK and import all required modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DuXga3GYBRtE"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install signal-ocean\n",
    "\n",
    "from signal_ocean import Connection\n",
    "connection = Connection(signal_ocean_api_key)\n",
    "\n",
    "from signal_ocean import Connection\n",
    "from signal_ocean.voyages import VoyagesAPI\n",
    "from signal_ocean.voyages import VesselClass, VesselClassFilter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "from datetime import date, datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Create instances of APIs used throughout this notebook:\n",
    "connection = Connection(signal_ocean_api_key)\n",
    "voyages_api = VoyagesAPI(connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4T_GmsSZBRtG"
   },
   "source": [
    "## Calculate Ton Charts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YgIXi6cGBRtH"
   },
   "source": [
    "In this example we are going to calculate the following metrics over time:\n",
    "* **Ton Days**: Deadweight of the vessel times the number of days the vessels was laden during a voyage.  \n",
    "* **Ton Miles**: Deadweight of the vessel times laden distance in miles during a voyage.  \n",
    "\n",
    "**Ton Days time series calculation:**  \n",
    "The goal is to distribute the ton days of a vessel across the days of the laden leg of the voyage. For this reason we calculate ton days per day, which is ton days divided by the number of laden days.\n",
    "\n",
    "**Ton Miles time series calculation:**   \n",
    "The goal is to distribute the ton miles of a vessel across the seagoing days of the laden leg of the voyage. For this reason we need to calculate ton miles per day between two voyage events (load events, stops) during the laden leg of the voyage.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ITKHHilBRtJ"
   },
   "source": [
    "### Get Data (Voyages Data API)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xAPScM05BRtK"
   },
   "source": [
    "- Define the Voyages Data parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "udxi6IXmUh6Y",
    "outputId": "2085c9c8-1f65-4539-e99f-dac7f803a6ab"
   },
   "outputs": [],
   "source": [
    "#get vessel class id for capesize\n",
    "vc = voyages_api.get_vessel_classes(VesselClassFilter('cape'))[0]\n",
    "vessel_class_id = vc.vessel_class_id\n",
    "vessel_class_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tZ-LE0ijBRtL"
   },
   "outputs": [],
   "source": [
    "# Areas of interest\n",
    "load_areas = ['Caribs', 'US Atlantic Coast', 'Brazil',\n",
    "              'East Coast Central America', 'US Gulf', 'East Coast Mexico']\n",
    "\n",
    "dis_areas = ['East Coast India', 'Pakistan / West Coast India', 'East Africa']\n",
    "\n",
    "\n",
    "# Start date for Ton Miles & Ton Days Calculation (Last 6 months)\n",
    "tonncharts_start_date = date.today() - relativedelta(months=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7UZyV-m3BRtN"
   },
   "source": [
    "Voyages Data API allows users to retrieve voyages based on voyage start date.\n",
    "Since we need all the port calls of the last six months to calculate ton days and ton miles, we will have to retrieve voyages that ended after tonncharts_start_date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qQXSIUUlBRtO"
   },
   "outputs": [],
   "source": [
    "voyages_start_date = tonncharts_start_date - relativedelta(months=6)\n",
    "\n",
    "voyages_flat = voyages_api.get_voyages_flat(\n",
    "    vessel_class_id=vessel_class_id, date_from=voyages_start_date\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LLxFN0fgBRtP"
   },
   "outputs": [],
   "source": [
    "voyages_df = pd.DataFrame(v.__dict__ for v in voyages_flat.voyages)\n",
    "events_df = pd.DataFrame(v.__dict__ for v in voyages_flat.events)\n",
    "events_details_df = pd.DataFrame(v.__dict__ for v in voyages_flat.event_details)\n",
    "geos_df = pd.DataFrame(v.__dict__ for v in voyages_flat.geos).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CrT_c5rqBRtQ"
   },
   "outputs": [],
   "source": [
    "# we will use only voyages that have ended after the tonncharts_start_date\n",
    "voyages_df.end_date = pd.to_datetime(voyages_df.end_date, errors = 'coerce', utc = True)\n",
    "voyages_df = voyages_df[voyages_df.end_date.dt.date >= tonncharts_start_date]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1KhN8GnABRtU"
   },
   "source": [
    "We need to merge the load events with the events details because we need to retrieve the start time of operation for each load port call. In case that a single load event has more than one event details, we should take the first one into account for retrieving start time of operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rsD0v9WABRtV"
   },
   "outputs": [],
   "source": [
    "load_events_with_start_time_of_operation = (\n",
    "    events_df[events_df.purpose == 'Load']\n",
    "    .merge(\n",
    "        events_details_df.loc[\n",
    "            (events_details_df.event_detail_type.isin(['Jetty','StS','Stop'])),\n",
    "            ['event_id','start_time_of_operation']],\n",
    "        how = 'left',\n",
    "        left_on = 'id',\n",
    "        right_on = 'event_id'\n",
    "    )\n",
    "    .groupby('event_id')\n",
    "    .head(1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DtY8LC-pBRtX"
   },
   "outputs": [],
   "source": [
    "# dataframe extended with vessels and geos information\n",
    "toncharts_df = (\n",
    "    pd.concat(\n",
    "        [load_events_with_start_time_of_operation,\n",
    "         events_df[~events_df.purpose.isin(['Load','Start'])]],\n",
    "        ignore_index = True\n",
    "    )\n",
    "    .merge(\n",
    "        voyages_df[\n",
    "            ['id','imo','deadweight','voyage_number','first_load_arrival_date',\n",
    "             'end_date','laycan_from',\n",
    "            'laden_distance','predicted_laden_distance']\n",
    "        ],\n",
    "        how = 'left',\n",
    "        left_on = 'voyage_id',\n",
    "        right_on = 'id',\n",
    "        suffixes = ['_ev','_voy']\n",
    "    ).merge(\n",
    "        geos_df,\n",
    "        how = 'inner',\n",
    "        left_on = 'geo_asset_id',\n",
    "        right_on = 'id',\n",
    "        suffixes = ['_vs','_geos']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kmsTQxljBRtY"
   },
   "outputs": [],
   "source": [
    "# get only port calls after the first load\n",
    "toncharts_df = toncharts_df.loc[toncharts_df['arrival_date'] >= toncharts_df['first_load_arrival_date']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L9Bb4pPYBRtZ"
   },
   "outputs": [],
   "source": [
    "toncharts_df['first_load_arrival_area'] = (\n",
    "    toncharts_df\n",
    "    .sort_values('arrival_date')\n",
    "    .groupby('voyage_id')\n",
    "    .area_name_level0_geos\n",
    "    .transform('first')\n",
    ")\n",
    "\n",
    "toncharts_df['last_discharge_arrival_area'] = (\n",
    "    toncharts_df\n",
    "    .sort_values('arrival_date')\n",
    "    .groupby('voyage_id')\n",
    "    .area_name_level0_geos\n",
    "    .transform('last')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hgJGvzSNBRta"
   },
   "outputs": [],
   "source": [
    "#filter on the load/discharge areas\n",
    "load_area_filter = (toncharts_df.first_load_arrival_area.isin(load_areas))\n",
    "discharge_area_filter = (toncharts_df.last_discharge_arrival_area.isin(dis_areas))\n",
    "\n",
    "toncharts_df = toncharts_df[load_area_filter & discharge_area_filter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pN6BpKbqBRtb"
   },
   "source": [
    "Here we introduce start_date as the first day of the laden leg for each voyage. Start date for a voyage is:  \n",
    "* start_time_of_operation if exists, else\n",
    "* laycan_from if exists, else\n",
    "* sailing_date of the first load port call minus 2 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ObDeBCHKBRtc"
   },
   "outputs": [],
   "source": [
    "condlist = [\n",
    "    toncharts_df.start_time_of_operation.notna(),\n",
    "    toncharts_df.laycan_from.notna()\n",
    "]\n",
    "\n",
    "choicelist = [toncharts_df.start_time_of_operation, toncharts_df.laycan_from]\n",
    "\n",
    "toncharts_df['start_date'] = np.select(\n",
    "    condlist, \n",
    "    choicelist, \n",
    "    default= (toncharts_df.sailing_date - timedelta(days=2))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X573dleIBRtc"
   },
   "outputs": [],
   "source": [
    "# voyage days calculation\n",
    "toncharts_df['voyage_days'] = (\n",
    "    toncharts_df['end_date'] - toncharts_df['start_date']\n",
    ") / np.timedelta64(1, 'D')\n",
    "\n",
    "toncharts_df['voyage_days'] = (\n",
    "    toncharts_df\n",
    "    .sort_values('arrival_date')\n",
    "    .groupby('voyage_id')\n",
    "    .voyage_days\n",
    "    .transform('first')\n",
    ")\n",
    "\n",
    "#we consider voyages that have lasted more than 250 days as noise and we filter them out\n",
    "toncharts_df = toncharts_df[toncharts_df['voyage_days'] <= 250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4m4uoIlOBRtd"
   },
   "outputs": [],
   "source": [
    "# ton days calculation\n",
    "toncharts_df['ton_days'] = toncharts_df.deadweight * toncharts_df.voyage_days\n",
    "toncharts_df['ton_days_per_day'] = toncharts_df.ton_days / toncharts_df.voyage_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DjQyExYLBRte"
   },
   "outputs": [],
   "source": [
    "# voyage miles calculation\n",
    "toncharts_df['voyage_miles'] = (\n",
    "    toncharts_df['laden_distance'].fillna(0) + \n",
    "    toncharts_df['predicted_laden_distance'].fillna(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LrqZ7IykBRtf"
   },
   "outputs": [],
   "source": [
    "# calculation of the date ranges in which ton days and ton miles will be distributed\n",
    "toncharts_df['next_arrival_date'] = (\n",
    "    toncharts_df\n",
    "    .sort_values('arrival_date')\n",
    "    .groupby('voyage_id')['arrival_date']\n",
    "    .shift(-1)\n",
    ")\n",
    "\n",
    "toncharts_df['tonmiles_daterange'] = (\n",
    "    toncharts_df\n",
    "    .apply(lambda row: pd.date_range(\n",
    "        row.sailing_date.date() + timedelta(days = 1), \n",
    "        row.next_arrival_date.date() - timedelta(days = 1)) if not pd.isnull(row.next_arrival_date) else [], \n",
    "    axis = 1)\n",
    ")\n",
    "\n",
    "toncharts_df['tondays_daterange'] = (\n",
    "    toncharts_df\n",
    "    .apply(lambda row: pd.date_range(\n",
    "        row.start_date.date(), \n",
    "        row.end_date.date()), \n",
    "    axis = 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1e9d4ujEBRtg"
   },
   "outputs": [],
   "source": [
    "#calculating seagoing days between events and total seagoing days of a voyage\n",
    "toncharts_df['seagoing_hours_between_events'] = (\n",
    "    toncharts_df['next_arrival_date'] - toncharts_df['sailing_date']\n",
    ") /np.timedelta64(1,'h')\n",
    "\n",
    "toncharts_df.loc[\n",
    "    toncharts_df['seagoing_hours_between_events'] < 1.0, \n",
    "    'seagoing_hours_between_events'] = 1.0\n",
    "\n",
    "toncharts_df['seagoing_days_between_events'] = toncharts_df['seagoing_hours_between_events']/24\n",
    "\n",
    "toncharts_df['seagoing_days'] = (\n",
    "    toncharts_df\n",
    "    .groupby('voyage_id')\n",
    "    .seagoing_days_between_events\n",
    "    .transform('sum')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IdGS5xEMBRth"
   },
   "outputs": [],
   "source": [
    "# calculating ton miles between events and total ton miles of a voyage\n",
    "toncharts_df['ton_miles'] = toncharts_df['deadweight']*toncharts_df['voyage_miles']\n",
    "\n",
    "toncharts_df['miles_between_events'] = (\n",
    "    toncharts_df['voyage_miles']*\n",
    "    toncharts_df['seagoing_days_between_events']/\n",
    "    toncharts_df['seagoing_days']\n",
    ")\n",
    "toncharts_df['ton_miles_between_events_per_day'] = (\n",
    "    toncharts_df['deadweight']*\n",
    "    toncharts_df['miles_between_events']/\n",
    "    toncharts_df['seagoing_days_between_events']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lwn5v_M3BRti"
   },
   "outputs": [],
   "source": [
    "def calculate_ton_miles():\n",
    "    # calculating ton miles and ton days time series\n",
    "    ton_miles_ts = (\n",
    "        toncharts_df.loc[\n",
    "            (load_area_filter & discharge_area_filter) &\n",
    "            (toncharts_df.purpose != 'Discharge'),\n",
    "            ['voyage_id','tonmiles_daterange',\n",
    "             'ton_miles_between_events_per_day']\n",
    "        ].dropna()\n",
    "        .explode('tonmiles_daterange')\n",
    "        .rename(\n",
    "            columns={\n",
    "                'tonmiles_daterange':'date',\n",
    "                'ton_miles_between_events_per_day':'ton_miles'\n",
    "            })\n",
    "        .drop_duplicates(subset = ['voyage_id','date'])\n",
    "        .groupby('date')\n",
    "        .sum()\n",
    "        .rolling(window=7)\n",
    "        .mean()\n",
    "    )   \n",
    "    return ton_miles_ts\n",
    "    \n",
    "def calculate_ton_days():\n",
    "    ton_days_ts = (\n",
    "        toncharts_df.loc[\n",
    "            (load_area_filter & discharge_area_filter),\n",
    "            ['voyage_id','tondays_daterange',\n",
    "             'ton_days_per_day']\n",
    "        ]\n",
    "        .explode('tondays_daterange')\n",
    "        .rename(\n",
    "            columns={\n",
    "                'tondays_daterange':'date',\n",
    "                'ton_days_per_day':'ton_days'\n",
    "            })\n",
    "        .drop_duplicates(subset = ['voyage_id','date'])\n",
    "        .groupby('date')\n",
    "        .sum()\n",
    "        .rolling(window=7)\n",
    "        .mean()\n",
    "    )\n",
    "    return ton_days_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z5TCJWRBBRtj"
   },
   "outputs": [],
   "source": [
    "def plot_ton_miles(ton_miles_ts):\n",
    "    tm = ton_miles_ts.loc[tonncharts_start_date:date.today()]/1000000\n",
    "\n",
    "    plt.figure(figsize=(15,6), dpi= 80)\n",
    "    plt.plot(tm.index, tm.ton_miles)\n",
    "\n",
    "\n",
    "    plt.title(\"TonMiles time series (7 days MA)\", fontsize=16)\n",
    "    plt.grid(axis='both', alpha=.3)\n",
    "    \n",
    "    plt.gca().set_ylabel(\"Million TonMiles\", fontsize=12)\n",
    "\n",
    "    # Remove borders\n",
    "    plt.gca().spines[\"top\"].set_alpha(0.0)    \n",
    "    plt.gca().spines[\"bottom\"].set_alpha(0.3)\n",
    "    plt.gca().spines[\"right\"].set_alpha(0.0)    \n",
    "    plt.gca().spines[\"left\"].set_alpha(0.3)   \n",
    "    plt.show()   \n",
    "\n",
    "def plot_ton_days(ton_days_ts):\n",
    "    td = ton_days_ts.loc[tonncharts_start_date:date.today()]/1000\n",
    "\n",
    "    plt.figure(figsize=(15,6), dpi= 80)\n",
    "    plt.plot(td.index, td.ton_days)\n",
    "\n",
    "\n",
    "    plt.title(\"TonDays time series (7 days MA)\", fontsize=16)\n",
    "    plt.grid(axis='both', alpha=.3)\n",
    "    \n",
    "    plt.gca().set_ylabel(\"Thousands TonDays\", fontsize=12)\n",
    "\n",
    "    # Remove borders\n",
    "    plt.gca().spines[\"top\"].set_alpha(0.0)    \n",
    "    plt.gca().spines[\"bottom\"].set_alpha(0.3)\n",
    "    plt.gca().spines[\"right\"].set_alpha(0.0)    \n",
    "    plt.gca().spines[\"left\"].set_alpha(0.3)   \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cFKPOcFWBRtk"
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 433
    },
    "id": "vrxbKwWMBRtl",
    "outputId": "10f39174-c2af-4ce0-c200-4a9d59a7795f"
   },
   "outputs": [],
   "source": [
    "ton_miles_ts = calculate_ton_miles()\n",
    "plot_ton_miles(ton_miles_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 433
    },
    "id": "-jc_HchABRto",
    "outputId": "630dbc1b-8b3d-4537-aa09-3fda7423b00f"
   },
   "outputs": [],
   "source": [
    "ton_days_ts = calculate_ton_days()\n",
    "plot_ton_days(ton_days_ts)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Copy of TonCharts.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
